
# ====================================================
# Settings.conf File
# ----------------------------------------------------

# This file will help you set the variables for Odyssey's 5 main scripts. 
# Note that some of these variables may not need to be changed as they are already set to various programs' recommended defaults. 
	# Changing these variables are thus optional and labeled as: "(OPTIONAL)"
# However, some of these variables (such as reference paths, working directory, and GWAS and Imputation Project Names) must be set by the user for Odyssey to function
	# Changing these variables are thus required and labeled as: "(REQUIRED)"
# Variables are listed in order of appearance and also under the script they appear in (although some are referenced by future scripts)
	# In this way you may choose to fill out the variables a little at a time instead of all at once
	# If you choose to fill out the script little by little, make sure you do not run a script for which you have not filled out the necessary (REQUIRED) variables

# ====================================================

# =================================================================================
# ========================== Configuration Variables ============================
# =================================================================================

# Setting up Odyssey is as easy as installing-running Singularity. Odyssey can also be run without Odyssey, however, this is not the recommended setup. Please follow the configuration instructions and pick your configuration options. Once that is complete type your configuration option in the setup variable below:


# How did you setup Odyssey? (Choose: '1' or '2') (REQUIRED)
	# If you setup Odyssey to incorporate Odyssey -- Option #1 -- then type 'One':
	# If you setup Odyssey independently of Odyssey -- Option #2 -- then type 'Two':
		OdysseySetup="One";

# =================================================================================
# ========================== DataPrep Module Variables ============================
# =================================================================================

# It is recommended that you run the BCFTools +fixref add-in so that the genetic files to be imputed will match the imputation reference -- and thus reduce the chance of imputation errors.
# This step performs the following actions:
	# 1: Downloads a reference build from 1000 genomes
	# 2: Converts the Plink data into a BCF so that it may be 'fixed' via +fixref which includes:
		# a. removing variants not present on the reference (this normally includes multiallelic SNPs due to Plink file formatting
		# b. flipping variants that are not flipped to the proper reference strand
		# c. removing variants whose variants do not match the reference (even after trying to flip the variant to fix this)

# Do you want to use the Fixref plugin to prep your data for imputation? (Boolean: T/F)
	# If T then the BCFTools Fixref addin will run the following steps listed below:
	# If F then only Positional Duplicates will be removed
		PerformFixref="F";

	# Fixref Plug Steps: This section allows you to run invididual steps of the Fixref plugin
	# -----------------------------------------------------------------------------------------
	#Do you need to download the Reference to Prep the Genotype Files with BCFTools? You only need to do this once (Boolean: T/F)
		# NOTE: As references are continually being updated you may want to check the links to make sure they are still current and/or the reference you desire.
		# The references files are:
			# Ref Genome: ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz
			# Annotation for Ref Genome:ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b150_GRCh37p13/VCF/All_20170710.vcf.gz
		DownloadRef="F";

	#Execute STEP 1?: Converts your input Plink files to a BCF file (Boolean: T/F)
		DataPrepStep1="F";

	#Execute STEP 2?: Aligns BCF File to the Reference Annotation and fixes coordinate errors and allele mismatches with BCFtools (Boolean: T/F)
		DataPrepStep2="F";

	#Execute STEP 3?: Sorts the reference-aligned BCF output and convert it back into Plink format for phasing -- also removes positional duplicates if they exist (Boolean: T/F)
		DataPrepStep3="F";

	#Save DataPrep Intermediate Files?: Saves all the intermediate files for troubleshooting purposes instead of deleting them (Boolean: T/F)
		# NOTE: Obviously if you are executing on a step-by-step basis, you should NOT remove the intermediate files	
		SaveDataPrepIntermeds="F"
	# -----------------------------------------------------------------------------------------


# Do you want to visualize your genomic data? (Boolean: T/F)
	# Sometimes it is helpful to see summary stats of genomic data. Visualizing heterozygosity, missingness, and IBD is often useful in performing quality control. The following R-based step will INTERACTIVELY walk you through data visualization through a series of prompts. Since this in an interactive process, this step should obviously NOT be run in batch mode.
	
	# WARNING: THIS GRAPHICAL AND INTERACTIVE R-BASED STEP REQUIRES X11 TO BE CONFIGURED ON THE HOST AND REMOTE SYSTEM. IF YOU ARE RUNNING ODYSSEY LOCALLY THEN YOU MAY IGNORE THIS WARNING
	
	# NOTE: This step performs analysis on a Plink .bed/.bim/.fam file located within ./1_Target/PLACE_NEW_PROJECT_TARGET_DATA_HERE/. Ideally, this step is run after running the previous BCFToolsFixRef step -- regardless of whether BCFTools was  used to prep the data -- PerformFixref=T -- or only positional duplicates were removed -- PerformFixref=F
	
	# If T then an interactive R script will run allowing you to visualize the following:
		# --missingness of genotypes and individuals
		# --Heterozygosity rates
		# --Related Individuals
		
	# This step will also allow you to write individual ID numbers to an exclusion list that can be used later to exclude from analysis
	
	# If F then this step will be skipped
		DataVisualization="T";


# ===========================================================================================================================================================================
# ============================================================= Variables Used for More than 1 Script ======================================================================
# ===========================================================================================================================================================================

# Set Your Working Directory (i.e. specify where you put the Odyssey Folder on your system): (REQUIRED)
  # Please include a "/" on the end of your directory path as it will make the output syntax easier to read
	WorkingDir="/N/dc2/scratch/ryeller/Odyssey/";
		
#----------------------------------------------------------------------------
# High Performance Cluster (HPC) Control Variables: 
#----------------------------------------------------------------------------		
		
# Enter Your Email to get Notifications from your HPC: (OPTIONAL)
	Email="ryeller@iupui.edu";	

# Does your system utilize Lustre Stripped Directories? (OPTIONAL)
	# Lustre stripping helps the file directories on HPS to prevent from being filled by distributing the files between harddrives
	# This is a good practice to use if available since it prevents "drive-full" errors
	# If you don't know what this is or your system doesn't utilize this feature you can safely ignore this option
	# Boolean Specify (T/F):
		LustreStrip="T";
		
# Are you using a HPS (High Performance System) that utilizes a job handler?
	# If you specify "T" then a PBS header will be included on Phasing, Imputation, and GWAS analysis scripts
	# If you specify "F" then only a Bash shebang will be included on Phasing, Imputation, and GWAS analysis scripts 
		HPS_Submit="T";
		
# Maximum Memory Allocation
	# Many of the later steps (especially for the GWAS Project) use a larger amount of memory (in comparison to the Imputation Project Steps)
	# Specify the maximum memory allocation you can dedicate (this will be used to limit Plink's memory allocation and the amount of memory R will be allowed if executing on a HPS
	# Specify in terms of GB
		Max_Memory="24";
		
# Maximum Walltime Request for HPC
	# Specify the walltime you want to dedicate to your job on the HPC
		Max_Walltime="01:00:00";
	
# ===========================================================================================================================================================================
# =================================================================== Imputation Project Variables ==========================================================================
# ===========================================================================================================================================================================

# Set Imputation Project Name: (REQUIRED)
  # This is the name that will identify the imputation project (by setting directory and file names) throughout the phasing and imputation processes
  # For example: "ImputationRun1"
  # NOTE: The Imputation Project Name must be a continuous string (i.e. do not include spaces)
	BaseName="Plates1-48_Test";

	
# ==================================================
#   1_ImputeProjectSetup-QC-Split Script Variables
# ==================================================

# Make sure only ONE PLink dataset is deposited in the "PLACE_NEW_PROJECT_TARGET_DATA_HERE" folder -- e.g. a .bed,.bim, and .fam
  # Data arising from the deposited file will henceforth be named as the BaseName you specified under the BaseName variable
  
# Do you need to download a Reference Panel for phasing and imputation?
	# If set to T (True) then Odyssey will download a default hg19 Reference Panel from the Impute2 Website:
		# https://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3.html
	# Note: You only need to perform this step once
	# Note: If you do not use the default reference panel you will need to find a suitable alternative and place it in ./Odyssey/Reference/
	
	DownloadDefaultRefPanel="F";


# ==============================================
#   2_PhasingScriptMaker Variables
# ==============================================

# Number of Threads to Use for SHAPEIT Phasing: (OPTIONAL)
	PhasingThreads="5";

# Toggles whether the X chromosome (Chr23) is Phased by Shapeit:
  # NOTE: Pipeline assumes Plink chromosome nomenclature. So X chromosome should be listed as 23
  # Boolean Specify (T/F):
	PhaseX="T";

# Submit the Phasing scripts after you create them:
	# WARNING: Executes ALL Scripts that were just created in the Phasing Script Folder
	# Boolean Specify (T/F):
		ExecutePhasingScripts="F";

	
# ---------------------------
# Reference Dataset Section: (OPTIONAL - If Using Homo Sapien Data and Using the "Default" Reference Dataset -- https://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3.html)
# ---------------------------
	# A Homo sapien reference dataset is used by SHAPEIT and IMPUTE2 and provided by the IMPUTE2 website
	# If you choose to use this reference dataset, you do not need to modify any of the following reference variables nor modify the reference dataset names
	# The reference dataset is based on 1000 Genomes haplotypes -- Phase 3 integrated variant set release in NCBI build 37 (hg19) coordinates (Updated 3 Aug 2015)
		# And was downloaded from https://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3.html
	# If you choose to use your own reference data you may need to alter some of the following variables in addition to potentially renaming the reference dataset files

# ----------------------Start of Ref Variable Section------------------------------------------------------
	
# The Phasing and Impute Scripts search the Reference folder for hap, legend, and genetic map files by using an egrep (extended regex grep) non case-sensitive search
		
		# Genetic Map -- ./Reference directory is searched for a genetic map file: Filename must contain "chr[#]" and "map" in any order in the filename
			
		# Legend -- ./Reference directory is searched for a legend file: Filename must contain "chr[#]" and "legend.gz" in the filename

		# Hap -- ./Reference directory is searched for a hap file: Filename must contain "chr[#]" and "hap.gz" in the filename

		# X Chromosome Identifier -- .Reference directory is searched for the X chromosome map,legend, and hap file: 
			# Filenames will be searched based on the XChromIdentifier variable (specified below)
				# Files will be identified by searching for the XChromIdentifier and "map","legend.gz", and "hap.gz"
					# For example, if XChromIdentifier = "NONPAR" then Odyssey will search for the map file by looking for "NONPAR" and "map" in any order
			
			XChromIdentifier="Chr23";

# ----------------------End of Ref Variable Section------------------------------------------------------
	

# ===========================================	
#   3a_ImputeScriptMaker Variables
# ===========================================

# Perform Error Analysis on Phasing Step
	# Will output the record of the the phased chromosomes who have 'error' or 'segmentation' errors output to their log files
	# Boolean Specify (T/F):	
		PhasingErrorAnalysis="F";

# Toggles whether the Autosomes and X chromosome (Chr23) is Imputed:
  # Boolean Specify (T/F):
	ImputeAutosomes="T";
	ImputeX="F";

# Control the Chromosome Batches of Imputation scripts that are created/executed:  (OPTIONAL)
	# Since some HPC's have limits on jobs submitted
		ImputeChrStart="6";
		ImputeChrEnd="6";

	
# Submit the Imputation scripts after you create them:
	# WARNING: Executes the scripts that were created in the Imputation Script Folder
	# Boolean Specify (T/F):
		ExecuteImputationScripts="T";
		
# Set a HPS Walltime limit for the Imputation Job: (OPTIONAL)
	ImputeWalltime="4:50:00";
		
# ============================================
#  3b_ConcatConvert Variables
# ============================================

# Perform Error Analysis on Imputation Step.
	# Output record/s of imputed chromosomes who have 'error' or 'segmentation' errors noted in their log files
	# Boolean Specify (T/F):
		ImputationErrorAnalysis="F";

# Concatenate the chromosomal segment .gen files into a single chromosomal .gen
	# Boolean Specify (T/F):
		ConcatImpute="F";
	
	# Manual Concatenation: If a concatenation failed you can specify the chromosome to re-concatenate 
		# e.g. to reconcatenate chr 12 specify ConcatStart=12 ConcatEnd=12
		ConcatStart="21";
		ConcatEnd="23";
		

# Analyze Imputation Quality Metrics (via a SNP Report)
	# Creates a SNP Report (.snpstat) that contains QC metrics
		# Boolean Specify (T/F):		
			AnalyzeINFO="F";
	# Specify an IMPUTE INFO score threshold (this will be used to create a list of QC "accepted" imputed variants) (REQUIRED)
		# Set to "0" to keep everything
			INFOThresh="0.3"
	# Creates a SNP list (INFOFiltered_Chr[#].list) that contains variants that pass an INFO QC metric (specified below), a MORESNP list (MOREINFOFiltered_Chr[#].list) that contains variant names and INFO scores of those that pass the INFO threshold, and a log file (.snpstatOut)
		# Boolean Specify (T/F):
			FilterINFO="T"
	# Manual Analyze Imputation Metric: If an analysis fails you can specify the chromosome to re-analyze 
		# e.g. to reconcatenate chr 12 specify ConcatStart=12 ConcatEnd=12
		INFOStart="1";
		INFOEnd="23";

# Convert the concatenated imputed .GEN into a .VCF:
	# File Conversion of IMPUTE Chromosomal Concatenated .gen File to VCF is Handled by PLINK 2.0
		# Boolean Specify (T/F):
			Convert2VCF="F";

# Use BCFTools to Merge/Concatenate the VCF Files Created by PLINK:
	# Once the data has been converted into a merged VCF you can either analyze the results in Plink or another analysis program (e.g. SNPTEST, GENABLE, etc.)
		# Boolean Specify (T/F):
			MergeVCF="F";
	# Number of Threads BCFTools should use to concatenate the Plink TEMP VCF Files to the Final VCF
		ConcatThreads="7";
		
# Cleanup Temporary Files -- this will remove many of the temporary files needed to make the final VCF
	# This saves a lot of space -- but intermediates may be useful for troubleshooting purposes
		KeepTemp="T";

			
		# --------------------- Parallel Processing Option ---------------------# 
		
		# If you have GNU Parallel Installed (or available as a HPS module like on our system) you can speed up considerably the concatenation and analysis process
		# But if you don't mind waiting a little longer then you can skip this section and concatenate in serial
	
			# If you are wanting to deal with the headaches of parallel processing then it is assumed that you know your way around configuring GNU-Parallel
			# For convenience GNU-Parallel may be loaded by modifying the "LOAD_PARALLEL" variable
			# For example GNU-Parallel is currently setup to load via a module since our HPS uses module (http://modules.sourceforge.net/man/module.html)
			# However, you could easily use the SET command to set an environment variable that is directed to the GNU-Parallel exec files via (e.g. SET PATH=%PATH%;/path/to/other/exec)
			# Or if you would like more control configuring to your system then you will need to modify 3b_ConcatenateSegments.sh
				# Since line numbers change with updates, I've placed a "GNU-Parallel Tag" that you can search for in a text browser to find the lines you that load GNU-Parallel in 3b_ConcatConvert.sh
					LOAD_PARALLEL="module load gnu-parallel";
				
		# Boolean Specify (T/F): (IF set to "F" then will run in Serial Mode)
			
		# Concatenate the .gen files in parallel
			ConcatParallel="T";
		# Analyze Imputation Quality Metrics (via a SNP Report) in parallel	
			AnalyzeINFOParallel="T";
		# Filter Imputation Results by INFO Metric
			FilterINFOParallel="T";
		# Convert the concatenated imputed .GEN into a .VCF
			ConvertParallel="T";
			
						
		# --------------------- Parallel Processing Option ---------------------#


# ===========================================================================================================================================================================
# ====================================================================== GWAS Project Variables =============================================================================
# ===========================================================================================================================================================================

# Specify the GWAS Project Name: (REQUIRED)
	# This will be used to set the GWAS Project folder and filenames for identification throughout the GWAS
	# For example a Project name is "BlueEye_GWAS"
	# NOTE: Similar to the Imputation Project name, all GWAS Project Names must be a continuous string of characters (no spaces)
		GWASRunName="RingCombined_Log_Rm3STDEV_GWASQC";

# Do you need to perform the pre-GWAS step of converting the dosage VCF into a dosage GWAS Pfile?
	# Note: You only need to do this once if you are using performing multiple GWAS on the same VCF
	# Boolean Specify (T/F):
		VCF2PGEN="F";

		
# Specify the Name of the PLINK formatted Phenotype File that should be placed in the following directory: ./Odyssey/GWAS/Phenotype/ (REQUIRED)
	Pheno_File="PhenoTransformed.txt";

	
# Specify the name of the phenotype you would like analyzed (this must match with the column name in the PLINK pheno file)
	GWASPhenoName="RingCombined";
	

# Load the dosage VCF you would like analyzed
	# You may either specify the name of the Imputation Project that contains the data (the dosage VCF) you want analyzed...
		ImputationProject2Analyze="Plates1-48_LessQC";
	
	# Or you may override the default setting and specify the full path of the dosage VCF file you want analyzed
		# Boolean Specify (T/F):
			GWASOverride="F";
		# If you said yes to the override then input the full file path to the dosage VCF you want analyzed 
			ManualVCFInput="./Impute/HGDP952_Perform/ConcatImputation/2DONE_HGDP952_Perform_Merged.vcf.gz";

		# Load Sex information file with the dosage VCF
			# You will need to load a file that contains sex information for your samples
			# By default the fam file from the target directory in the Imputation Project is loaded alongside the dosage VCF
			# If you choose to do the GWASOverride above, then you will have to specify the path to the fam file that contains sex information
				ManualSexInput="/N/dc2/scratch/ryeller/Odyssey/Target/HGDP952_Perform/Ody1_HGDP952_Perform_Pre-ImputeQC2.fam";
	

# Specify the PLINK options you would like enacted for the GWAS: (REQUIRED)
	# If you must direct Plink to a file either use the full file path or give the path in relation to ./Odyssey (as it is the current working directory)
	# Flags included by default are --pfile (loads dosage data), --pheno (loads pheno data), --pheno-name (loads pheno name from pheno file), --threads (using GWAS_Threads Variable Setting), --memory (using Max_Memory Variable Setting), --out (sets the output directory)
		PLINK_OPTIONS="--glm sex hide-covar --geno 0.05 --hwe 0.0001 --maf 0.01 --covar /N/dc2/scratch/ryeller/Odyssey/GWAS/Phenotype/PhenoTransformed.txt --covar-name Age --remove /N/dc2/scratch/ryeller/Odyssey/GWAS/RmQC3STDEV.txt";


# Specify the number of the threads you intend to utilize for the GWAS analysis (OPTIONAL)
	GWAS_Threads="2";

	
# Submit the GWAS scripts after you create them: (REQUIRED)
	# WARNING: Executes Plink analysis and R visualization script that was created in the GWAS Project Analysis Folder
	# Boolean Specify (T/F):
		ExecuteGWASScripts="T";

	
	
	
	
	
	
	